{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\\\Users\\\\eiti mittal\\\\Downloads\\\\data_F1score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_pred_random_forest</th>\n",
       "      <th>y_pred_logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639816</td>\n",
       "      <td>0.531904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>0.414496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.623815</td>\n",
       "      <td>0.569883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506616</td>\n",
       "      <td>0.443674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418302</td>\n",
       "      <td>0.369532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_act  y_pred_random_forest  y_pred_logistic\n",
       "0      1              0.639816         0.531904\n",
       "1      0              0.490993         0.414496\n",
       "2      1              0.623815         0.569883\n",
       "3      1              0.506616         0.443674\n",
       "4      0              0.418302         0.369532"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true values are binary and are classified in two classes:-0,1.\n",
    "F1 score is a classification metrics but here we are trying to compare binary true labels with continuous predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests and logistic regression are classification models that outputs probabilities. Therefore all these y_predicted values are actually the probabilities of y belonging to classes 0 or 1 and thus should lie between 0 <y_pred_prob <1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17142946899999997, 0.930520528)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data['y_pred_random_forest']),max(data['y_pred_random_forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00021747799999999998, 0.999762052)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data['y_pred_logistic']),max(data['y_pred_logistic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default threshhold used by scikit learn for binary probabilistic based models is 0.5, so we'll find actual predicted values using threshhold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y_pred_binary_random_forest']=(data['y_pred_random_forest'] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y_pred_binary_logistic']=(data['y_pred_logistic'] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_pred_random_forest</th>\n",
       "      <th>y_pred_logistic</th>\n",
       "      <th>y_pred_binary_random_forest</th>\n",
       "      <th>y_pred_binary_logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639816</td>\n",
       "      <td>0.531904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>0.414496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.623815</td>\n",
       "      <td>0.569883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506616</td>\n",
       "      <td>0.443674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418302</td>\n",
       "      <td>0.369532</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_act  y_pred_random_forest  y_pred_logistic  y_pred_binary_random_forest  \\\n",
       "0      1              0.639816         0.531904                            1   \n",
       "1      0              0.490993         0.414496                            0   \n",
       "2      1              0.623815         0.569883                            1   \n",
       "3      1              0.506616         0.443674                            1   \n",
       "4      0              0.418302         0.369532                            0   \n",
       "\n",
       "   y_pred_binary_logistic  \n",
       "0                       1  \n",
       "1                       0  \n",
       "2                       1  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the TP, TN, FP, FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_confmat(actual, predicted):\n",
    "\n",
    "    classes = np.unique(actual) #extract the different classes\n",
    "    matrix = np.zeros((len(classes), len(classes))) #initialize the confusion matrix with zeros\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "\n",
    "            matrix[i, j] = np.sum((actual == classes[i]) & (predicted == classes[j]))\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5519., 2360.],\n",
       "       [2832., 5047.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_random_forest=comp_confmat(data['y_act'],data['y_pred_binary_random_forest'])\n",
    "conf_matrix_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5425., 2454.],\n",
       "       [3600., 4279.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_logistic=comp_confmat(data['y_act'],data['y_pred_binary_logistic'])\n",
    "conf_matrix_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Precision and recall for both the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean of recall and precision values for both the classes as they have equal weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of random forest:  0.6705165630156111\n",
      "precision of random forest:  0.6711307063452374\n"
     ]
    }
   ],
   "source": [
    "recall_rf = (np.diag(conf_matrix_random_forest) / np.sum(conf_matrix_random_forest, axis = 1)).mean()\n",
    "precision_rf = (np.diag(conf_matrix_random_forest) / np.sum(conf_matrix_random_forest, axis = 0)).mean()\n",
    "print(\"recall of random forest: \",recall_rf)\n",
    "print(\"precision of random forest: \",precision_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of logistic regression:  0.6158141896179719\n",
      "precision of logistic regresion:  0.6183172722272119\n"
     ]
    }
   ],
   "source": [
    "recall_lr = (np.diag(conf_matrix_logistic) / np.sum(conf_matrix_logistic, axis = 1)).mean()\n",
    "precision_lr = (np.diag(conf_matrix_logistic) / np.sum(conf_matrix_logistic, axis = 0)).mean()\n",
    "print(\"recall of logistic regression: \",recall_lr)\n",
    "print(\"precision of logistic regresion: \",precision_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to compute the F score for different values of beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(p,r,beta):\n",
    "    score=(((beta**2)+1)*p*r)/(((beta**2)*p)+r)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the F score at b##eta 0.5, 1, and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671007787694254\n",
      "0.6708234941173873\n",
      "0.6706393017458937\n"
     ]
    }
   ],
   "source": [
    "print(f_score(precision_rf,recall_rf,0.5))\n",
    "print(f_score(precision_rf,recall_rf,1))\n",
    "print(f_score(precision_rf,recall_rf,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617815029154131\n",
      "0.6170631925290971\n",
      "0.6163131835425678\n"
     ]
    }
   ],
   "source": [
    "print(f_score(precision_lr,recall_lr,0.5))\n",
    "print(f_score(precision_lr,recall_lr,1))\n",
    "print(f_score(precision_lr,recall_lr,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_rf=f_score(precision_rf,recall_rf,1)\n",
    "f1_score_lr=f_score(precision_lr,recall_lr,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7879\n",
       "0    7879\n",
       "Name: y_act, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y_act'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, this is an application of binary classifier on a balanced dataset\n",
    "\n",
    "For a balanced class data set with equal importance/weight given to both classes, a model with a  F1 score closer to 1 is a better model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of random forest:  0.6708234941173873\n",
      "F1 score of logistic regression:  0.6170631925290971\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of random forest: \",f1_score_rf)\n",
    "print(\"F1 score of logistic regression: \",f1_score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      7879\n",
      "           1       0.68      0.64      0.66      7879\n",
      "\n",
      "    accuracy                           0.67     15758\n",
      "   macro avg       0.67      0.67      0.67     15758\n",
      "weighted avg       0.67      0.67      0.67     15758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data['y_act'], data['y_pred_binary_random_forest']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64      7879\n",
      "           1       0.64      0.54      0.59      7879\n",
      "\n",
      "    accuracy                           0.62     15758\n",
      "   macro avg       0.62      0.62      0.61     15758\n",
      "weighted avg       0.62      0.62      0.61     15758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data['y_act'], data['y_pred_binary_logistic']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
